# 文本处理

[TOC]

### 只提取中文

```python
import re
def just_chinese(strings):
    regStr = ".*?([\u4E00-\u9FA5]+).*?"
    expr = ''.join(re.findall(regStr, strings))
    if expr:
        return expr
    return '\n'
```

### 切句

```python
import re
def cut_sentence(text, whole=False):
    '''

    :param text:
    :param whole: 是否取整句
    :return:
    '''
    if whole:
        pattern = r'\.|/|;|\'|`|\[|\]|<|>|\?|:|"|\{|\}|\~|!|@|#|\$|%|\^|&|\(|\)|-|=|\_|\+|。|、|；|‘|’|【|】|·|！| |…|（|）'
    else:
        pattern = r',|\.|/|;|\'|`|\[|\]|<|>|\?|:|"|\{|\}|\~|!|@|#|\$|%|\^|&|\(|\)|-|=|\_|\+|，|。|、|；|‘|’|【|】|·|！| |…|（|）'
    result_list = re.split(pattern, text)
    return result_list
```

### jieba抽取句的关键词(tfidf)

```python
import jieba.analyse
keywords = jieba.analyse.extract_tags(
        review, topK=20, withWeight=True, allowPOS=('n', 'a', 'ad'))
果味 1.4296524297779647
省心 1.4182980208335811
清香 1.0579030496130413
常备 0.8496729905537379
```

<details>
<summary>jieba词性表</summary>
<pre><code>
|      | - a 形容词                   |
| ---- | ---------------------------- |
|      | - ad 副形词                  |
|      | - ag 形容词性语素            |
|      | - an 名形词                  |
|      | - b 区别词                   |
|      | - c 连词                     |
|      | - d 副词                     |
|      | - df                         |
|      | - dg 副语素                  |
|      | - e 叹词                     |
|      | - f 方位词                   |
|      | - g 语素                     |
|      | - h 前接成分                 |
|      | - i 成语                     |
|      | - j 简称略称                 |
|      | - k 后接成分                 |
|      | - l 习用语                   |
|      | - m 数词                     |
|      | - mg                         |
|      | - mq 数量词                  |
|      | - n 名词                     |
|      | - ng 名词性语素              |
|      | - nr 人名                    |
|      | - nrfg                       |
|      | - nrt                        |
|      | - ns 地名                    |
|      | - nt 机构团体名              |
|      | - nz 其他专名                |
|      | - o 拟声词                   |
|      | - p 介词                     |
|      | - q 量词                     |
|      | - r 代词                     |
|      | - rg 代词性语素              |
|      | - rr 人称代词                |
|      | - rz 指示代词                |
|      | - s 处所词                   |
|      | - t 时间词                   |
|      | - tg 时语素                  |
|      | - u 助词                     |
|      | - ud 结构助词 得             |
|      | - ug 时态助词                |
|      | - uj 结构助词 的             |
|      | - ul 时态助词 了             |
|      | - uv 结构助词 地             |
|      | - uz 时态助词 着             |
|      | - v 动词                     |
|      | - vd 副动词                  |
|      | - vg 动词性语素              |
|      | - vi 不及物动词              |
|      | - vn 名动词                  |
|      | - vq                         |
|      | - x 非语素词（包含标点符号） |
|      | - y 语气词                   |
|      | - z 状态词                   |
|      | - zg                         |
</code></pre>
</details>


### tf-idf排序

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

def get_order_by_tf_idf(question, paragraphs):
    sorted_order = []
    corpus = [question]
    for order, text in paragraphs.items():
        corpus.append(text)
        sorted_order.append(order)
    tf_idf = TfidfVectorizer().fit_transform(corpus)
    cosine_similarities = linear_kernel(tf_idf[0:1], tf_idf).flatten()[1:]
    sorted_similarities = sorted(enumerate(cosine_similarities), key=lambda x: x[1])
    idx = [i[0] for i in sorted_similarities][::-1]
    return [sorted_order[index] for index in idx]
```

### 清洗文本

```python
def clean_text(strings):
    regStr = '[\u3002\uff1b\uff0c\uff1a\u201c\u201d\uff08\uff09\u3001\uff1f\u300a\u300b\u4e00-\u9fa50-9]'
    expr = re.findall(regStr, strings)
    if expr:
        return ''.join(expr)
    return '\n'
```

### 词性分词

```python
import jieba.posseg as jp
print(jp.lcut('我爱西樵山'))
[pair(‘我’, ‘r’), pair(‘爱’, ‘v’), pair(‘西樵山’, ‘ns’)]
```





