[TOC]

## DSSM模型(双塔模型)

https://zhuanlan.zhihu.com/p/136253355![img](https://pic2.zhimg.com/80/v2-ba79344ae838977c80b1236a6d2281c5_1440w.webp)

![img](https://pic4.zhimg.com/80/v2-1b3a07af31f139a88421ddf903600d27_1440w.webp)



## CoSENT

https://spaces.ac.cn/archives/8847

### Sentence-BERT

练阶段是将u,v,|u−v|（其中|u−v|是指u−v的每个元素都取绝对值后构成的向量）拼接起来做为特征，后面接一个全连接层做2分类（如果是NLI数据集则是3分类），而在预测阶段，还是跟普通的句向量模型一样，先计算句向量然后算cos值作为相似度。如下图所示：

<img src="/Users/zhz/Library/Application Support/typora-user-images/image-20230130190422023.png" alt="image-20230130190422023" style="zoom:200%;" />

解释：我们可以想象正样本对的u−v主要分布在一个半径较小的球面附近，而负样本对的u−v分布在一个半径较大的球面附近，也就是说，初始阶段u−v本身就有聚类倾向，我们接下来只需要根据标签信息强化这种聚类倾向加上绝对值变成|u−v|，将球面变为局部的球盖（或者说将球体变成锥形），此时就可以用Dense分类层来分类了。

至于u,v的拼接，笔者认为是用来消除各向异性的

问题：因为训练和预测的不一致性，存在一定的概率会“训崩”，导致我们很难确定对哪些训练过程的调整会给预测结果带来正面帮助。

### SimCSE

![image-20230130192319068](/Users/zhz/Library/Application Support/typora-user-images/image-20230130192319068.png)

#### unsupervised

对于无监督的部分，最核心的创新点就是使用droupout来对文本增加噪音，从而构造一个正样本对，而负样本对则是在batch中选取的其它句子。其实对于图像任务来说，做数据增强其实非常简单，有各种的手段。但是对于NLP任务来说，传统的方法有词替，裁剪以及回译，但是作者发现这些方法都没有简单的dropout效果好。

dropout 作为正样本，batch内其余样本为负样本：

![image-20230130192802504](/Users/zhz/Library/Application Support/typora-user-images/image-20230130192802504.png)

#### supervised

这一部分的句子对直接采用了NLI数据集的数据，因为其中有天然的正负例句子对。构成三元组，优化目标如下：

![image-20230130192915835](/Users/zhz/Library/Application Support/typora-user-images/image-20230130192915835.png)

### CoSENT1

基于二元组的supervised SimCSE版本，损失函数：

![image-20230130193759318](/Users/zhz/Library/Application Support/typora-user-images/image-20230130193759318.png)

代码：**https://github.com/bojone/CoSENT**

![image-20230130194209428](/Users/zhz/Library/Application Support/typora-user-images/image-20230130194209428.png)

### 交互式（Interaction-based）和特征式（Representation-based)

交互式由于使得两个文本能够进行充分的比较，所以它准确性通常较好，但明显的缺点是在检索场景的效率较差；而特征式则可以提前计算并缓存好句向量，所以它有着较高的效率，但由于句子间的交互程度较浅，所以通常效果不如交互式。

#### 阈值确定

![image-20230131095320586](/Users/zhz/Library/Application Support/typora-user-images/image-20230131095320586.png)

代码：**https://github.com/bojone/CoSENT/tree/main/accuracy**

### 多标签分类loss

https://spaces.ac.cn/archives/7359#%E7%BB%9F%E4%B8%80%E7%9A%84loss%E5%BD%A2%E5%BC%8F

![image-20230131165753777](/Users/zhz/Library/Application Support/typora-user-images/image-20230131165753777.png)

是基于softmax在多标签分类的自然推广

### Circle Loss

文中提出了一种基于对的相似性优化方法，基于对的优化的方法目的都是最大化类内相似性 sp 同时最小化类间相似性 sn。文中发现大多数的损失函数，包括triplet loss 和softmax激活函数加交叉熵损失函数，都是使 sn 和 sp 嵌入到一个相似性对，并且去减小 (sn - sp) 。这样的优化方式是不够灵活的，因为其对每一个单一相似性分数的惩罚强度是相等的。该文中的初衷是如果一个相似性得分远离最优的中心，那么其应该被更多的关注(即惩罚)。基于这个目的，文中重新加权那些欠优化的相似性得分。为了重新加权那些欠优化的分数，文中提出了**Circle loss,** 之所以叫这个名字是因为其决策边界是一个圆。**Circle loss**对基于类标签和基于对的标签都有一个统一的公式。



![image-20230201155055150](/Users/zhz/Library/Application Support/typora-user-images/image-20230201155055150.png)

![image-20230201155253088](/Users/zhz/Library/Application Support/typora-user-images/image-20230201155253088.png)
